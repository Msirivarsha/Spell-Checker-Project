{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a6f9708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80145a22",
   "metadata": {},
   "source": [
    "## 1. Finding unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9361e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115585\n",
      "32198\n"
     ]
    }
   ],
   "source": [
    "with open('big.txt','r') as fd:\n",
    "    lines=fd.readlines()\n",
    "    words=[]\n",
    "    for line in lines:\n",
    "        words+=re.findall('\\w+',line.lower())\n",
    "        \n",
    "print(len(words))\n",
    "vocab=list(set(words))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb43cea",
   "metadata": {},
   "source": [
    "## 2. Finding the Probabilty Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b301da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words.count('Book') #print how many times a word appears in the dataset\n",
    "# words.count('the')/len(words) #to find probability of each word to appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00042ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 32198/32198 [10:10<00:00, 52.71it/s]\n"
     ]
    }
   ],
   "source": [
    "word_probability={}\n",
    "for word in tqdm(vocab):\n",
    "    word_probability[word]=float(words.count(word)/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf864ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('besprinkled', 1.7927813658304835e-06),\n",
       " ('mobbing', 8.963906829152417e-07),\n",
       " ('bedford', 1.7927813658304835e-06),\n",
       " ('inheritance', 1.4342250926643868e-05),\n",
       " ('lamentations', 8.963906829152417e-07),\n",
       " ('emancipators', 8.963906829152417e-07),\n",
       " ('droop', 2.6891720487457255e-06),\n",
       " ('ugliness', 8.963906829152417e-07),\n",
       " ('ear', 4.123397141410112e-05),\n",
       " ('_main', 2.6891720487457255e-06)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_probability.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e11181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07154004401278254"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_probability['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c967955",
   "metadata": {},
   "source": [
    "## 3. Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752b7a44",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dceb9b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(word):\n",
    "    \n",
    "    parts=[]\n",
    "    for i in range(len(word)+1):\n",
    "        parts+=[(word[:i],word[i:])]\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2b7f8",
   "metadata": {},
   "source": [
    "###  3.1 Delete\n",
    "'loave' -> 'love'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "88cacc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oave', 'lave', 'love', 'loae', 'loav', 'loave']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delete(word):\n",
    "    \n",
    "    output=[]\n",
    "    for l,r in split(word):\n",
    "        output.append(l+r[1:])\n",
    "    return output\n",
    "\n",
    "delete('loave')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca2e6d8",
   "metadata": {},
   "source": [
    "### 3.2 Swap\n",
    "'lvoe' -> 'love'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "46284d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vloe', 'love', 'lveo']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def swap(word):\n",
    "    \n",
    "    output=[]\n",
    "    for l,r in split(word):\n",
    "        if(len(r)>1):\n",
    "            output.append(l+r[1]+r[0]+r[2:])\n",
    "    return output\n",
    "\n",
    "swap('lvoe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbee52a",
   "metadata": {},
   "source": [
    "### 3.3 Replace\n",
    "'lave' -> 'love'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6506510b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace(word):\n",
    "    \n",
    "    characters='abcdefghijklmnopqrstuvwxyz'\n",
    "    output=[]\n",
    "    \n",
    "    for l,r in split(word):\n",
    "        for char in characters:\n",
    "            output.append(l+char+r[1:])\n",
    "    return output\n",
    "\n",
    "len(replace('lave'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed231f",
   "metadata": {},
   "source": [
    "### 3.4 Insert\n",
    "'lve' -> 'love'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e00e7499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def insert(word):\n",
    "    \n",
    "    characters='abcdefghijklmnopqrstuvwxyz'\n",
    "    output=[]\n",
    "    \n",
    "    for l,r in split(word):\n",
    "        for char in characters:\n",
    "            output.append(l+char+r)\n",
    "    return output\n",
    "\n",
    "len(insert('lve'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cfd557",
   "metadata": {},
   "source": [
    "## 4. Finding the prediction(Level 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96104e1b",
   "metadata": {},
   "source": [
    "### 4.1 Combining Possible words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9f5e8ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit(word):\n",
    "    return list(set(insert(word)+delete(word)+swap(word)+replace(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4607b4d",
   "metadata": {},
   "source": [
    "### 4.2 predicting the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "96d64f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check_edit_1(word,count=5):\n",
    "    \n",
    "    suggested_words=edit(word)\n",
    "    output=[]\n",
    "    \n",
    "    for wrd in suggested_words:\n",
    "        if wrd in word_probability.keys():\n",
    "            output.append([wrd,word_probability[wrd]])\n",
    "            \n",
    "    return list(pd.DataFrame(output,columns=['word','prob']).sort_values(by='prob',ascending=False).head(count)['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5ca7dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['family']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_check_edit_1('famili')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fd29d",
   "metadata": {},
   "source": [
    "## 5. Finding the Prediction(Level 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abc53a",
   "metadata": {},
   "source": [
    "### 5.1 Combining Possible Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "87d20af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vasili', 'family', 'familiar', 'families', 'fail']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spell_check_edit_2(word,count=5):\n",
    "\n",
    "    output=[]\n",
    "    suggested_words=edit(word)       #level one edit\n",
    "    \n",
    "    for e1 in edit(word):\n",
    "        suggested_words +=edit(e1)   #level two edit\n",
    "        \n",
    "    suggested_words=list(set(suggested_words))\n",
    "    \n",
    "    for wrd in suggested_words:\n",
    "        if wrd in word_probability.keys():\n",
    "            output.append([wrd,word_probability[wrd]])\n",
    "    return list(pd.DataFrame(output,columns=['word','prob']).sort_values(by='prob',ascending=False).head(count)['word'].values)\n",
    "\n",
    "spell_check_edit_2('famili')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
